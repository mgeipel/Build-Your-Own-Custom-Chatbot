{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "The dataset comprises the abstracts of the popular book on [www.goodreads.com](https://www.goodreads.com) for the years 2022 to 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0404af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "# get the api key from the environment variable\n",
    "openai.api_key = os.getenv(\"VOC_OPENAI_API_KEY\") \n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=openai.api_key,  \n",
    "    base_url=openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "years = [\"2022\", \"2023\", \"2024\"]\n",
    "\n",
    "# Download the HTML files\n",
    "for year in years:\n",
    "    resp = requests.get(f\"https://www.goodreads.com/book/popular_by_date/{year}\")\n",
    "    with open(f\"goodreads_{year}.html\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(resp.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a595980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of books: 45\n",
      "                                                text\n",
      "0  #\\n1\\nThe Housemaid (The Housemaid, #1)\\nFreid...\n",
      "1  #\\n2\\nIt Starts with Us (It Ends with Us, #2)\\...\n",
      "2  #\\n3\\nReminders of Him\\nColleen Hoover\\n4.36\\n...\n",
      "3  #\\n4\\nBook Lovers\\nEmily Henry\\n4.12\\n1m\\n \\nr...\n",
      "4  #\\n5\\nTomorrow, and Tomorrow, and Tomorrow\\nGa...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# read the data\n",
    "list_items = []\n",
    "for year in years:\n",
    "    with open(f\"goodreads_{year}.html\", \"r\", encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "\n",
    "    # parse the HTML\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    list_items.extend(soup.find_all('article', class_='BookListItem'))\n",
    "\n",
    "books_abstracts = list([item.get_text(\"\\n\") for item in list_items])\n",
    "\n",
    "# cleanup the text\n",
    "pattern = re.compile(r'\\s*(\\d+\\.\\d+)\\s*(\\d+k).*\\s*Want to read\\s*')\n",
    "books_abstracts = [pattern.sub(' ', item) for item in books_abstracts]\n",
    "\n",
    "# save the data\n",
    "df = pd.DataFrame(books_abstracts, columns=[\"text\"])\n",
    "df.to_csv(\"goodreads_books.csv\", index=False)\n",
    "\n",
    "print(f\"Number of books: {len(df)}\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "045158d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#\\n1\\nThe Housemaid (The Housemaid, #1)\\nFreid...</td>\n",
       "      <td>[-0.004109004512429237, -0.0223678145557642, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#\\n2\\nIt Starts with Us (It Ends with Us, #2)\\...</td>\n",
       "      <td>[-0.005668665282428265, 0.004265830852091312, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#\\n3\\nReminders of Him\\nColleen Hoover\\n4.36\\n...</td>\n",
       "      <td>[0.003345254110172391, -0.012298277579247952, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#\\n4\\nBook Lovers\\nEmily Henry\\n4.12\\n1m\\n \\nr...</td>\n",
       "      <td>[-0.0031754060182720423, -0.013626998290419579...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#\\n5\\nTomorrow, and Tomorrow, and Tomorrow\\nGa...</td>\n",
       "      <td>[0.010921248234808445, -0.01308033149689436, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  #\\n1\\nThe Housemaid (The Housemaid, #1)\\nFreid...   \n",
       "1  #\\n2\\nIt Starts with Us (It Ends with Us, #2)\\...   \n",
       "2  #\\n3\\nReminders of Him\\nColleen Hoover\\n4.36\\n...   \n",
       "3  #\\n4\\nBook Lovers\\nEmily Henry\\n4.12\\n1m\\n \\nr...   \n",
       "4  #\\n5\\nTomorrow, and Tomorrow, and Tomorrow\\nGa...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.004109004512429237, -0.0223678145557642, -...  \n",
       "1  [-0.005668665282428265, 0.004265830852091312, ...  \n",
       "2  [0.003345254110172391, -0.012298277579247952, ...  \n",
       "3  [-0.0031754060182720423, -0.013626998290419579...  \n",
       "4  [0.010921248234808445, -0.01308033149689436, -...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code taken from the class notebook casestudy.ipynb\n",
    "# Create a list to store the embeddings\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in range(0, len(df), batch_size):\n",
    "    # Send text data to OpenAI model to get embeddings\n",
    "    response = client.embeddings.create(\n",
    "        input=df.iloc[i:i+batch_size][\"text\"].tolist(),\n",
    "        model=EMBEDDING_MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    # Add embeddings to list\n",
    "    embeddings.extend([data.embedding for data in response.data])\n",
    "\n",
    "# Add embeddings list to dataframe\n",
    "df[\"embeddings\"] = embeddings\n",
    "df.to_csv(\"goodreads_books_embedded.csv\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef34e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "TODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "582f0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code taken from the class notebook casestudy.ipynb and from https://github.com/openai/openai-python/blob/release-v0.28.0/openai/embeddings_utils.py\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def distances_from_embeddings(query_embedding,embeddings):\n",
    "    distances = [\n",
    "        1-cosine_similarity(query_embedding, embedding)\n",
    "        for embedding in embeddings\n",
    "    ]\n",
    "    return distances\n",
    "\n",
    "def get_embedding(text, engine=EMBEDDING_MODEL_NAME):\n",
    "    return client.embeddings.create(\n",
    "        input=[text],\n",
    "        model=engine\n",
    "    ).data[0].embedding\n",
    "\n",
    "def get_rows_sorted_by_relevance(question, df):\n",
    "    \"\"\"\n",
    "    Function that takes in a question string and a dataframe containing\n",
    "    rows of text and associated embeddings, and returns that dataframe\n",
    "    sorted from least to most relevant for that question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get embeddings for the question text\n",
    "    question_embeddings = get_embedding(question, engine=EMBEDDING_MODEL_NAME)\n",
    "    \n",
    "    # Make a copy of the dataframe and add a \"distances\" column containing\n",
    "    # the cosine distances between each row's embeddings and the\n",
    "    # embeddings of the question\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        question_embeddings,\n",
    "        df_copy[\"embeddings\"].values,\n",
    "    )\n",
    "    \n",
    "    # Sort the copied dataframe by the distances and return it\n",
    "    # (shorter distance = more relevant so we sort in ascending order)\n",
    "    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#\\n4\\nBook Lovers\\nEmily Henry\\n4.12\\n1m\\n \\nr...</td>\n",
       "      <td>[-0.0031754060182720423, -0.013626998290419579...</td>\n",
       "      <td>0.181074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>#\\n1\\nFunny Story\\nEmily Henry\\n4.24\\n719k\\n \\...</td>\n",
       "      <td>[0.0029939222149550915, -0.02424975298345089, ...</td>\n",
       "      <td>0.181479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>#\\n13\\nThe Seven Year Slip\\nAshley Poston\\n4.2...</td>\n",
       "      <td>[0.003417385509237647, -0.007594190072268248, ...</td>\n",
       "      <td>0.187588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>#\\n7\\nDivine Rivals (Letters of Enchantment, #...</td>\n",
       "      <td>[0.0022449044045060873, -0.028142593801021576,...</td>\n",
       "      <td>0.188190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#\\n5\\nTomorrow, and Tomorrow, and Tomorrow\\nGa...</td>\n",
       "      <td>[0.010921248234808445, -0.01308033149689436, -...</td>\n",
       "      <td>0.195343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "3   #\\n4\\nBook Lovers\\nEmily Henry\\n4.12\\n1m\\n \\nr...   \n",
       "30  #\\n1\\nFunny Story\\nEmily Henry\\n4.24\\n719k\\n \\...   \n",
       "27  #\\n13\\nThe Seven Year Slip\\nAshley Poston\\n4.2...   \n",
       "21  #\\n7\\nDivine Rivals (Letters of Enchantment, #...   \n",
       "4   #\\n5\\nTomorrow, and Tomorrow, and Tomorrow\\nGa...   \n",
       "\n",
       "                                           embeddings  distances  \n",
       "3   [-0.0031754060182720423, -0.013626998290419579...   0.181074  \n",
       "30  [0.0029939222149550915, -0.02424975298345089, ...   0.181479  \n",
       "27  [0.003417385509237647, -0.007594190072268248, ...   0.187588  \n",
       "21  [0.0022449044045060873, -0.028142593801021576,...   0.188190  \n",
       "4   [0.010921248234808445, -0.01308033149689436, -...   0.195343  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking = get_rows_sorted_by_relevance(\"A book about love\", df)\n",
    "ranking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c403f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the class notebook casestudy.ipynb \n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def create_prompt(question, df, max_token_count):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "You are an expert for popular books published in the last 3 years.\n",
    "Answer the question based on the context below, and if the question\n",
    "can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                            len(tokenizer.encode(question))\n",
    "    \n",
    "    context = []\n",
    "    for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "        \n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "        \n",
    "        # Add the row of text to the list if we haven't exceeded the max\n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74280b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the class notebook casestudy.ipynb \n",
    "\n",
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "def answer_question(\n",
    "    question, df, max_prompt_tokens=1800, max_answer_tokens=150\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a question, a dataframe containing rows of text, and a maximum\n",
    "    number of desired tokens in the prompt and response, return the\n",
    "    answer to the question according to an OpenAI Completion model\n",
    "    \n",
    "    If the model produces an error, return an empty string\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = create_prompt(question, df, max_prompt_tokens)\n",
    "    \n",
    "    try:\n",
    "        response = client.completions.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n",
    "    \n",
    "def answer_question_with_model_only(\n",
    "    question, max_answer_tokens=150\n",
    "):\n",
    "   \n",
    "    try:\n",
    "        response = client.completions.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=\"You are an expert for popular books published in the last 3 years. Answer the following question: \" + question,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4901c850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Listen for the Lie\" by Amy Tintera or \"Never Lie\" by Freida McFadden could both be good options for a detective story reccomendation.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Can you reccomend a detective story book?\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run with an empty dataframe\n",
    "answer_question(\"Can you reccomend a detective story book?\", df[0:0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4fa8d9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, I can recommend \"The Woman in the Window\" by A.J. Finn. It is a gripping thriller about an agoraphobic woman who witnesses a crime from her window. As she tries to uncover the truth, she begins to question her own sanity. The twists and turns in this book will keep readers on the edge of their seats until the very end. It was published in 2018 and became an instant New York Times bestseller. It has also been optioned for a movie adaptation.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question_with_model_only(\"Can you reccomend a detective story book?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f646989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, Britney Spears wrote \"The Woman in Me\" in the last 3 years.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Did Britney write anything recently?\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run with an empty dataframe\n",
    "answer_question(\"Did Britney write anything recently?\", df[0:0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2eeb7ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, Britney Spears has not published any books in the last 3 years. Her most recent book, \"A Mother\\'s Gift,\" was published in 2001. She has stated in interviews that she has no current plans to write any new books.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question_with_model_only(\"Did Britney write anything recently?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d52b327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
